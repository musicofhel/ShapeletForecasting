{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Time Warping (DTW) Analysis Demo\n",
    "\n",
    "This notebook demonstrates the DTW module capabilities for financial time series pattern matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import DTW modules\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.dtw import (\n",
    "    DTWCalculator, FastDTW, ConstrainedDTW,\n",
    "    SimilarityEngine, PatternClusterer, DTWVisualizer\n",
    ")\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic DTW Example\n",
    "\n",
    "Let's start with a simple example comparing two time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate two similar but shifted sine waves\n",
    "t1 = np.linspace(0, 4*np.pi, 100)\n",
    "t2 = np.linspace(0, 4*np.pi, 120)\n",
    "\n",
    "# Create patterns with different phases and noise\n",
    "pattern1 = np.sin(t1) + 0.1 * np.random.randn(100)\n",
    "pattern2 = np.sin(t2 + 0.5) + 0.1 * np.random.randn(120)\n",
    "\n",
    "# Plot the patterns\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(pattern1, label='Pattern 1', linewidth=2)\n",
    "plt.plot(pattern2, label='Pattern 2', linewidth=2)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Two Time Series Patterns')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute DTW distance\n",
    "dtw_calc = DTWCalculator(return_cost_matrix=True)\n",
    "result = dtw_calc.compute(pattern1, pattern2)\n",
    "\n",
    "print(f\"DTW Distance: {result.distance:.4f}\")\n",
    "print(f\"Normalized Distance: {result.normalized_distance:.4f}\")\n",
    "print(f\"Optimal Path Length: {len(result.path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the alignment\n",
    "visualizer = DTWVisualizer(figsize=(12, 8))\n",
    "visualizer.plot_alignment(pattern1, pattern2, result.path, \n",
    "                         title=\"DTW Alignment Visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the cost matrix\n",
    "if result.cost_matrix is not None:\n",
    "    visualizer.plot_cost_matrix(result.cost_matrix, result.path,\n",
    "                               title=\"DTW Cost Matrix with Optimal Path\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Comparing DTW Algorithms\n",
    "\n",
    "Let's compare the performance and results of different DTW variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate longer time series for comparison\n",
    "n_points = 500\n",
    "x = np.cumsum(np.random.randn(n_points)) + np.sin(np.linspace(0, 10*np.pi, n_points))\n",
    "y = np.cumsum(np.random.randn(n_points)) + np.sin(np.linspace(0, 10*np.pi, n_points))\n",
    "\n",
    "# Normalize\n",
    "x = (x - x.mean()) / x.std()\n",
    "y = (y - y.mean()) / y.std()\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(x, alpha=0.7, label='Series X')\n",
    "plt.plot(y, alpha=0.7, label='Series Y')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Normalized Value')\n",
    "plt.title('Long Time Series for DTW Comparison')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Compare different DTW methods\n",
    "methods = {\n",
    "    'Standard DTW': DTWCalculator(),\n",
    "    'FastDTW (r=1)': FastDTW(radius=1),\n",
    "    'FastDTW (r=5)': FastDTW(radius=5),\n",
    "    'Sakoe-Chiba (w=20)': ConstrainedDTW(constraint_type='sakoe_chiba', constraint_param=20),\n",
    "    'Itakura': ConstrainedDTW(constraint_type='itakura', constraint_param=2.0)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, calculator in methods.items():\n",
    "    start_time = time.time()\n",
    "    result = calculator.compute(x, y)\n",
    "    comp_time = time.time() - start_time\n",
    "    \n",
    "    results[name] = {\n",
    "        'distance': result.distance,\n",
    "        'normalized_distance': result.normalized_distance,\n",
    "        'time': comp_time\n",
    "    }\n",
    "    \n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  Distance: {result.distance:.4f}\")\n",
    "    print(f\"  Normalized: {result.normalized_distance:.4f}\")\n",
    "    print(f\"  Time: {comp_time:.4f}s\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Distance comparison\n",
    "methods_list = list(results.keys())\n",
    "distances = [results[m]['normalized_distance'] for m in methods_list]\n",
    "ax1.bar(range(len(methods_list)), distances)\n",
    "ax1.set_xticks(range(len(methods_list)))\n",
    "ax1.set_xticklabels(methods_list, rotation=45, ha='right')\n",
    "ax1.set_ylabel('Normalized DTW Distance')\n",
    "ax1.set_title('Distance Comparison')\n",
    "\n",
    "# Time comparison\n",
    "times = [results[m]['time'] for m in methods_list]\n",
    "ax2.bar(range(len(methods_list)), times)\n",
    "ax2.set_xticks(range(len(methods_list)))\n",
    "ax2.set_xticklabels(methods_list, rotation=45, ha='right')\n",
    "ax2.set_ylabel('Computation Time (seconds)')\n",
    "ax2.set_title('Speed Comparison')\n",
    "ax2.set_yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pattern Similarity Analysis\n",
    "\n",
    "Now let's analyze similarities between multiple patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate diverse patterns\n",
    "n_patterns = 12\n",
    "patterns = []\n",
    "labels = []\n",
    "\n",
    "for i in range(n_patterns):\n",
    "    t = np.linspace(0, 4*np.pi, 100)\n",
    "    \n",
    "    if i < 4:  # Sine variations\n",
    "        pattern = np.sin(t * (1 + i*0.2)) + 0.1*np.random.randn(100)\n",
    "        labels.append(f\"Sine_{i+1}\")\n",
    "    elif i < 8:  # Trend patterns\n",
    "        pattern = 0.1 * t + np.sin(t) * (0.5 + (i-4)*0.2) + 0.1*np.random.randn(100)\n",
    "        labels.append(f\"Trend_{i-3}\")\n",
    "    else:  # Random walk\n",
    "        pattern = np.cumsum(np.random.randn(100)) * 0.1\n",
    "        labels.append(f\"Random_{i-7}\")\n",
    "    \n",
    "    # Normalize\n",
    "    pattern = (pattern - pattern.mean()) / (pattern.std() + 1e-8)\n",
    "    patterns.append(pattern)\n",
    "\n",
    "# Visualize all patterns\n",
    "fig, axes = plt.subplots(3, 4, figsize=(15, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (pattern, label) in enumerate(zip(patterns, labels)):\n",
    "    axes[i].plot(pattern)\n",
    "    axes[i].set_title(label)\n",
    "    axes[i].set_ylim(-3, 3)\n",
    "    \n",
    "plt.suptitle('Pattern Library', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute similarity matrix\n",
    "engine = SimilarityEngine(dtw_type='fast', radius=2, n_jobs=4)\n",
    "sim_results = engine.compute_similarity_matrix(patterns, labels)\n",
    "\n",
    "print(f\"Similarity matrix shape: {sim_results['similarity_matrix'].shape}\")\n",
    "print(f\"Mean similarity: {np.mean(sim_results['similarity_matrix']):.3f}\")\n",
    "print(f\"Std similarity: {np.std(sim_results['similarity_matrix']):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize similarity matrix\n",
    "visualizer.plot_similarity_matrix(\n",
    "    sim_results['similarity_matrix'],\n",
    "    labels=labels,\n",
    "    title=\"Pattern Similarity Matrix\",\n",
    "    annotate=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find most similar patterns\n",
    "stats = engine.compute_pattern_statistics(sim_results['similarity_matrix'], labels)\n",
    "\n",
    "print(\"Most Similar Pattern Pairs:\")\n",
    "for i, pair in enumerate(stats['most_similar_pairs'][:5]):\n",
    "    print(f\"{i+1}. {pair['labels'][0]} <-> {pair['labels'][1]}: {pair['similarity']:.3f}\")\n",
    "\n",
    "print(\"\\nMost Connected Patterns (highest average similarity):\")\n",
    "for i, conn in enumerate(stats['pattern_connectivity'][:5]):\n",
    "    print(f\"{i+1}. {conn['label']}: {conn['avg_similarity']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pattern Clustering\n",
    "\n",
    "Let's cluster the patterns based on their DTW similarities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform hierarchical clustering\n",
    "clusterer = PatternClusterer(\n",
    "    clustering_method='hierarchical',\n",
    "    linkage_method='average',\n",
    "    n_clusters=3\n",
    ")\n",
    "\n",
    "cluster_results = clusterer.fit_predict(\n",
    "    patterns,\n",
    "    similarity_matrix=sim_results['similarity_matrix']\n",
    ")\n",
    "\n",
    "print(f\"Number of clusters: {cluster_results['n_clusters']}\")\n",
    "print(f\"Silhouette score: {cluster_results['silhouette_score']:.3f}\")\n",
    "print(\"\\nCluster assignments:\")\n",
    "for label, cluster in zip(labels, cluster_results['labels']):\n",
    "    print(f\"  {label}: Cluster {cluster}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot dendrogram\n",
    "clusterer.plot_dendrogram(\n",
    "    cluster_results['linkage_matrix'],\n",
    "    labels=labels,\n",
    "    figsize=(12, 6)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize clustered patterns\n",
    "visualizer.plot_cluster_patterns(\n",
    "    patterns,\n",
    "    cluster_results['labels'],\n",
    "    cluster_results['cluster_centers'],\n",
    "    n_examples=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cluster heatmap\n",
    "clusterer.plot_cluster_heatmap(\n",
    "    1 - sim_results['similarity_matrix'],  # Convert to distance\n",
    "    cluster_results['labels'],\n",
    "    pattern_labels=labels,\n",
    "    figsize=(10, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Real Financial Data Analysis\n",
    "\n",
    "Let's apply DTW to real financial time series data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load financial data\n",
    "data_dir = Path('../data/processed')\n",
    "tickers = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'META']\n",
    "\n",
    "price_patterns = []\n",
    "pattern_labels = []\n",
    "\n",
    "for ticker in tickers:\n",
    "    file_path = data_dir / f\"{ticker}_processed.h5\"\n",
    "    if file_path.exists():\n",
    "        with pd.HDFStore(file_path, 'r') as store:\n",
    "            df = store['data']\n",
    "            \n",
    "            # Extract recent price pattern (last 100 days)\n",
    "            returns = df['returns'].iloc[-100:].values\n",
    "            \n",
    "            # Normalize\n",
    "            returns_norm = (returns - returns.mean()) / (returns.std() + 1e-8)\n",
    "            \n",
    "            price_patterns.append(returns_norm)\n",
    "            pattern_labels.append(ticker)\n",
    "\n",
    "if price_patterns:\n",
    "    print(f\"Loaded {len(price_patterns)} financial patterns\")\n",
    "    \n",
    "    # Visualize patterns\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for pattern, label in zip(price_patterns, pattern_labels):\n",
    "        plt.plot(pattern, label=label, linewidth=2)\n",
    "    plt.xlabel('Days')\n",
    "    plt.ylabel('Normalized Returns')\n",
    "    plt.title('Financial Return Patterns (Last 100 Days)')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No financial data found. Using synthetic data instead.\")\n",
    "    # Generate synthetic financial-like patterns\n",
    "    price_patterns = []\n",
    "    pattern_labels = ['Stock_A', 'Stock_B', 'Stock_C', 'Stock_D', 'Stock_E']\n",
    "    \n",
    "    for i, label in enumerate(pattern_labels):\n",
    "        # Simulate returns with different characteristics\n",
    "        trend = 0.0001 * i * np.arange(100)\n",
    "        volatility = 0.01 * (1 + i * 0.2)\n",
    "        returns = trend + volatility * np.random.randn(100)\n",
    "        returns = (returns - returns.mean()) / (returns.std() + 1e-8)\n",
    "        price_patterns.append(returns)\n",
    "    \n",
    "    print(\"Generated synthetic financial patterns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute financial pattern similarities\n",
    "fin_engine = SimilarityEngine(dtw_type='fast', radius=2)\n",
    "fin_sim_results = fin_engine.compute_similarity_matrix(price_patterns, pattern_labels)\n",
    "\n",
    "# Visualize\n",
    "visualizer.plot_similarity_matrix(\n",
    "    fin_sim_results['similarity_matrix'],\n",
    "    labels=pattern_labels,\n",
    "    title=\"Stock Return Pattern Similarities\",\n",
    "    annotate=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find most similar stock patterns\n",
    "fin_stats = fin_engine.compute_pattern_statistics(\n",
    "    fin_sim_results['similarity_matrix'], \n",
    "    pattern_labels\n",
    ")\n",
    "\n",
    "print(\"Most Similar Stock Pairs:\")\n",
    "for i, pair in enumerate(fin_stats['most_similar_pairs'][:3]):\n",
    "    print(f\"{i+1}. {pair['labels'][0]} <-> {pair['labels'][1]}: {pair['similarity']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Interactive Visualizations\n",
    "\n",
    "Create interactive visualizations using Plotly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive DTW alignment\n",
    "if len(price_patterns) >= 2:\n",
    "    dtw_calc = DTWCalculator()\n",
    "    result = dtw_calc.compute(price_patterns[0], price_patterns[1])\n",
    "    \n",
    "    fig = visualizer.create_interactive_alignment(\n",
    "        price_patterns[0], \n",
    "        price_patterns[1], \n",
    "        result.path,\n",
    "        title=f\"DTW Alignment: {pattern_labels[0]} vs {pattern_labels[1]}\",\n",
    "        labels=(pattern_labels[0], pattern_labels[1])\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive similarity matrix\n",
    "fig = visualizer.create_interactive_similarity_matrix(\n",
    "    fin_sim_results['similarity_matrix'],\n",
    "    pattern_labels,\n",
    "    title=\"Interactive Stock Similarity Matrix\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Performance Analysis\n",
    "\n",
    "Let's analyze the performance characteristics of different DTW methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance comparison on different series lengths\n",
    "lengths = [50, 100, 200, 500]\n",
    "methods_perf = {\n",
    "    'Standard': DTWCalculator(),\n",
    "    'FastDTW': FastDTW(radius=2),\n",
    "    'Constrained': ConstrainedDTW(constraint_param=10)\n",
    "}\n",
    "\n",
    "performance_data = {name: {'time': [], 'lengths': lengths} for name in methods_perf}\n",
    "\n",
    "for length in lengths:\n",
    "    print(f\"Testing length: {length}\")\n",
    "    \n",
    "    # Generate test data\n",
    "    x = np.random.randn(length)\n",
    "    y = np.random.randn(length)\n",
    "    \n",
    "    for name, calculator in methods_perf.items():\n",
    "        # Time multiple runs\n",
    "        times = []\n",
    "        for _ in range(5):\n",
    "            start = time.time()\n",
    "            _ = calculator.compute(x, y)\n",
    "            times.append(time.time() - start)\n",
    "        \n",
    "        avg_time = np.mean(times)\n",
    "        performance_data[name]['time'].append(avg_time)\n",
    "        print(f\"  {name}: {avg_time:.4f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot performance comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for name, data in performance_data.items():\n",
    "    plt.plot(data['lengths'], data['time'], marker='o', label=name, linewidth=2)\n",
    "\n",
    "plt.xlabel('Time Series Length')\n",
    "plt.ylabel('Computation Time (seconds)')\n",
    "plt.title('DTW Performance Comparison')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.yscale('log')\n",
    "plt.show()\n",
    "\n",
    "# Calculate speedup\n",
    "standard_times = performance_data['Standard']['time']\n",
    "fast_times = performance_data['FastDTW']['time']\n",
    "speedups = [s/f for s, f in zip(standard_times, fast_times)]\n",
    "\n",
    "print(\"\\nFastDTW Speedup over Standard DTW:\")\n",
    "for length, speedup in zip(lengths, speedups):\n",
    "    print(f\"  Length {length}: {speedup:.2f}x faster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Basic DTW computation** and alignment visualization\n",
    "2. **Comparison of DTW algorithms** (Standard, FastDTW, Constrained)\n",
    "3. **Pattern similarity analysis** using DTW distance matrices\n",
    "4. **Hierarchical clustering** of time series patterns\n",
    "5. **Real financial data analysis** with stock return patterns\n",
    "6. **Interactive visualizations** for exploring DTW results\n",
    "7. **Performance analysis** showing the trade-offs between methods\n",
    "\n",
    "The DTW module provides powerful tools for:\n",
    "- Finding similar patterns in financial time series\n",
    "- Clustering related market behaviors\n",
    "- Building pattern libraries for prediction\n",
    "- Efficient computation with FastDTW for large-scale analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
