{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering Demo\n",
    "\n",
    "This notebook demonstrates the feature engineering capabilities developed in Sprint 4:\n",
    "- Pattern-based features from wavelets and DTW\n",
    "- Technical indicators\n",
    "- Transition matrix features\n",
    "- Feature selection and importance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up paths\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import feature engineering components\n",
    "from src.features import (\n",
    "    PatternFeatureExtractor,\n",
    "    TechnicalIndicators,\n",
    "    TransitionMatrixBuilder,\n",
    "    FeaturePipeline,\n",
    "    FeatureSelector\n",
    ")\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Sample Financial Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic financial data\n",
    "np.random.seed(42)\n",
    "n_days = 1000\n",
    "dates = pd.date_range(start='2020-01-01', periods=n_days, freq='D')\n",
    "\n",
    "# Generate price data with trends and patterns\n",
    "trend = np.linspace(100, 150, n_days)\n",
    "seasonal = 10 * np.sin(2 * np.pi * np.arange(n_days) / 252)  # Annual cycle\n",
    "noise = np.random.normal(0, 2, n_days)\n",
    "price = trend + seasonal + noise\n",
    "\n",
    "# Add some volatility clusters\n",
    "volatility_regime = np.random.choice([0.5, 2.0], size=n_days, p=[0.8, 0.2])\n",
    "price += np.random.normal(0, volatility_regime)\n",
    "\n",
    "# Create OHLCV data\n",
    "df = pd.DataFrame({\n",
    "    'open': price + np.random.uniform(-1, 1, n_days),\n",
    "    'high': price + np.abs(np.random.normal(0, 1, n_days)),\n",
    "    'low': price - np.abs(np.random.normal(0, 1, n_days)),\n",
    "    'close': price,\n",
    "    'volume': np.random.lognormal(15, 0.5, n_days)\n",
    "}, index=dates)\n",
    "\n",
    "# Ensure OHLC consistency\n",
    "df['high'] = df[['open', 'high', 'close']].max(axis=1)\n",
    "df['low'] = df[['open', 'low', 'close']].min(axis=1)\n",
    "\n",
    "print(f\"Generated {len(df)} days of financial data\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the price data\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8), sharex=True)\n",
    "\n",
    "# Price plot\n",
    "ax1.plot(df.index, df['close'], label='Close Price', linewidth=1)\n",
    "ax1.fill_between(df.index, df['low'], df['high'], alpha=0.3, label='High-Low Range')\n",
    "ax1.set_ylabel('Price')\n",
    "ax1.set_title('Synthetic Financial Time Series')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Volume plot\n",
    "ax2.bar(df.index, df['volume'], alpha=0.7, width=1)\n",
    "ax2.set_ylabel('Volume')\n",
    "ax2.set_xlabel('Date')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Technical Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute technical indicators\n",
    "tech_calculator = TechnicalIndicators()\n",
    "indicators = tech_calculator.compute_all_indicators(df)\n",
    "\n",
    "print(f\"Computed {len(indicators.columns)} technical indicators\")\n",
    "print(\"\\nSample indicators:\")\n",
    "print(indicators.columns[:20].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some key indicators\n",
    "fig, axes = plt.subplots(4, 1, figsize=(14, 12), sharex=True)\n",
    "\n",
    "# Price with moving averages\n",
    "ax = axes[0]\n",
    "ax.plot(df.index, df['close'], label='Close', linewidth=1, alpha=0.8)\n",
    "ax.plot(df.index, indicators['sma_20'], label='SMA 20', linewidth=2)\n",
    "ax.plot(df.index, indicators['ema_50'], label='EMA 50', linewidth=2)\n",
    "ax.set_ylabel('Price')\n",
    "ax.set_title('Price with Moving Averages')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# RSI\n",
    "ax = axes[1]\n",
    "ax.plot(df.index, indicators['rsi_14'], label='RSI(14)', color='purple')\n",
    "ax.axhline(y=70, color='r', linestyle='--', alpha=0.5, label='Overbought')\n",
    "ax.axhline(y=30, color='g', linestyle='--', alpha=0.5, label='Oversold')\n",
    "ax.set_ylabel('RSI')\n",
    "ax.set_ylim(0, 100)\n",
    "ax.set_title('Relative Strength Index')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# MACD\n",
    "ax = axes[2]\n",
    "ax.plot(df.index, indicators['macd'], label='MACD', linewidth=2)\n",
    "ax.plot(df.index, indicators['macd_signal'], label='Signal', linewidth=2)\n",
    "ax.bar(df.index, indicators['macd_histogram'], label='Histogram', alpha=0.3)\n",
    "ax.set_ylabel('MACD')\n",
    "ax.set_title('MACD Indicator')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Bollinger Bands\n",
    "ax = axes[3]\n",
    "ax.plot(df.index, df['close'], label='Close', linewidth=1, color='black')\n",
    "ax.plot(df.index, indicators['bb_upper_20'], label='Upper Band', linestyle='--', alpha=0.7)\n",
    "ax.plot(df.index, indicators['bb_middle_20'], label='Middle Band', linestyle='-', alpha=0.7)\n",
    "ax.plot(df.index, indicators['bb_lower_20'], label='Lower Band', linestyle='--', alpha=0.7)\n",
    "ax.fill_between(df.index, indicators['bb_lower_20'], indicators['bb_upper_20'], alpha=0.1)\n",
    "ax.set_ylabel('Price')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_title('Bollinger Bands')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pattern-Based Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract pattern-based features\n",
    "pattern_extractor = PatternFeatureExtractor(\n",
    "    wavelet='morl',\n",
    "    n_patterns=10,\n",
    "    pattern_length=20\n",
    ")\n",
    "\n",
    "# Prepare windows for pattern extraction\n",
    "window_size = 100\n",
    "windows = []\n",
    "for i in range(window_size, len(df)):\n",
    "    window = df['close'].iloc[i-window_size:i].values\n",
    "    windows.append(window)\n",
    "\n",
    "windows = np.array(windows)\n",
    "print(f\"Created {len(windows)} windows of size {window_size}\")\n",
    "\n",
    "# Fit and transform\n",
    "pattern_features = pattern_extractor.fit_transform(windows)\n",
    "print(f\"\\nExtracted {len(pattern_features.columns)} pattern-based features\")\n",
    "pattern_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some pattern features\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "# Select features to plot\n",
    "features_to_plot = [\n",
    "    'wavelet_energy',\n",
    "    'wavelet_entropy',\n",
    "    'dtw_min_distance',\n",
    "    'pattern_transitions'\n",
    "]\n",
    "\n",
    "for i, feature in enumerate(features_to_plot):\n",
    "    if feature in pattern_features.columns:\n",
    "        ax = axes[i]\n",
    "        ax.plot(pattern_features[feature].values, linewidth=1)\n",
    "        ax.set_title(f'{feature}')\n",
    "        ax.set_xlabel('Window Index')\n",
    "        ax.set_ylabel('Feature Value')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Transition Matrix Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pattern sequences for transition analysis\n",
    "# Simulate pattern sequences (in real use, these would come from pattern matching)\n",
    "n_sequences = 100\n",
    "sequence_length = 50\n",
    "n_patterns = 5\n",
    "\n",
    "# Generate sequences with some structure\n",
    "sequences = []\n",
    "for _ in range(n_sequences):\n",
    "    # Create sequence with tendency to stay in same state\n",
    "    sequence = []\n",
    "    current_state = np.random.randint(0, n_patterns)\n",
    "    for _ in range(sequence_length):\n",
    "        sequence.append(current_state)\n",
    "        # Transition probability\n",
    "        if np.random.random() < 0.3:  # 30% chance to transition\n",
    "            current_state = np.random.randint(0, n_patterns)\n",
    "    sequences.append(sequence)\n",
    "\n",
    "# Build transition matrices\n",
    "transition_builder = TransitionMatrixBuilder(\n",
    "    n_patterns=n_patterns,\n",
    "    pattern_length=20,\n",
    "    max_order=2\n",
    ")\n",
    "\n",
    "transition_builder.fit(sequences)\n",
    "transition_features = transition_builder.transform(sequences)\n",
    "\n",
    "print(f\"Extracted {len(transition_features.columns)} transition features\")\n",
    "transition_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize transition matrix\n",
    "trans_matrix = transition_builder.get_transition_matrix(order=1)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(trans_matrix, annot=True, fmt='.2f', cmap='YlOrRd',\n",
    "            xticklabels=[f'P{i}' for i in range(n_patterns)],\n",
    "            yticklabels=[f'P{i}' for i in range(n_patterns)])\n",
    "plt.title('Pattern Transition Matrix (Order 1)')\n",
    "plt.xlabel('Next Pattern')\n",
    "plt.ylabel('Current Pattern')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot stationary distribution\n",
    "stationary = transition_builder.get_stationary_distribution()\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(range(n_patterns), stationary)\n",
    "plt.xlabel('Pattern')\n",
    "plt.ylabel('Stationary Probability')\n",
    "plt.title('Stationary Distribution of Patterns')\n",
    "plt.xticks(range(n_patterns), [f'Pattern {i}' for i in range(n_patterns)])\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Complete Feature Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create complete feature pipeline\n",
    "pipeline = FeaturePipeline(\n",
    "    use_pattern_features=True,\n",
    "    use_technical_indicators=True,\n",
    "    use_transition_features=True,\n",
    "    wavelet='morl',\n",
    "    n_patterns=10,\n",
    "    pattern_length=20,\n",
    "    feature_window=100,\n",
    "    prediction_horizon=5,\n",
    "    scaler_type='standard'\n",
    ")\n",
    "\n",
    "# Fit pipeline\n",
    "print(\"Fitting feature pipeline...\")\n",
    "pipeline.fit(df)\n",
    "\n",
    "# Transform data\n",
    "print(\"\\nTransforming data...\")\n",
    "all_features = pipeline.transform(df)\n",
    "\n",
    "print(f\"\\nTotal features extracted: {len(all_features.columns)}\")\n",
    "print(f\"Feature matrix shape: {all_features.shape}\")\n",
    "print(f\"\\nFeature categories:\")\n",
    "print(f\"- Technical indicators\")\n",
    "print(f\"- Pattern-based features\")\n",
    "print(f\"- Transition features\")\n",
    "print(f\"- Price features\")\n",
    "print(f\"- Time features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create target variable\n",
    "target = pipeline.create_target(df, target_type='classification')\n",
    "print(f\"Target variable: {target.name}\")\n",
    "print(f\"Class distribution:\")\n",
    "print(target.value_counts())\n",
    "\n",
    "# Align features and target\n",
    "mask = all_features.index.isin(target.dropna().index)\n",
    "X = all_features[mask]\n",
    "y = target[mask]\n",
    "\n",
    "print(f\"\\nAligned data shape: X={X.shape}, y={y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Selection and Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection\n",
    "selector = FeatureSelector(\n",
    "    task_type='classification',\n",
    "    selection_method='rf',  # Random Forest importance\n",
    "    n_features=30,\n",
    "    correlation_threshold=0.95\n",
    ")\n",
    "\n",
    "# Fit selector\n",
    "print(\"Performing feature selection...\")\n",
    "X_selected = selector.fit_transform(X.fillna(0), y)\n",
    "\n",
    "print(f\"\\nSelected {len(selector.selected_features_)} features from {X.shape[1]} total features\")\n",
    "print(f\"Removed {len(selector.removed_correlated_)} highly correlated features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importance\n",
    "fig = selector.plot_feature_importance(top_n=20, figsize=(10, 8))\n",
    "plt.show()\n",
    "\n",
    "# Get feature report\n",
    "feature_report = selector.get_feature_report()\n",
    "print(\"\\nTop 10 most important features:\")\n",
    "print(feature_report.head(10)[['feature', 'importance_score', 'rank', 'selected']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot correlation matrix of selected features\n",
    "fig = selector.plot_correlation_matrix(selected_only=True, figsize=(12, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze feature types in selected features\n",
    "selected_features = selector.selected_features_\n",
    "\n",
    "feature_types = {\n",
    "    'Technical': [],\n",
    "    'Pattern': [],\n",
    "    'Transition': [],\n",
    "    'Price': [],\n",
    "    'Time': []\n",
    "}\n",
    "\n",
    "for feature in selected_features:\n",
    "    if any(ind in feature for ind in ['sma', 'ema', 'rsi', 'macd', 'bb', 'atr']):\n",
    "        feature_types['Technical'].append(feature)\n",
    "    elif any(pat in feature for pat in ['wavelet', 'dtw', 'cluster', 'pattern']):\n",
    "        feature_types['Pattern'].append(feature)\n",
    "    elif any(trans in feature for trans in ['trans', 'entropy', 'stability']):\n",
    "        feature_types['Transition'].append(feature)\n",
    "    elif any(price in feature for price in ['returns', 'volatility', 'ratio']):\n",
    "        feature_types['Price'].append(feature)\n",
    "    elif any(time in feature for time in ['day', 'month', 'quarter']):\n",
    "        feature_types['Time'].append(feature)\n",
    "\n",
    "# Plot distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "categories = list(feature_types.keys())\n",
    "counts = [len(features) for features in feature_types.values()]\n",
    "\n",
    "plt.bar(categories, counts, color='skyblue', edgecolor='navy')\n",
    "plt.xlabel('Feature Category')\n",
    "plt.ylabel('Number of Selected Features')\n",
    "plt.title('Distribution of Selected Features by Category')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for i, count in enumerate(counts):\n",
    "    plt.text(i, count + 0.5, str(count), ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Selected features by category:\")\n",
    "for category, features in feature_types.items():\n",
    "    if features:\n",
    "        print(f\"\\n{category} ({len(features)}):\")\n",
    "        print(f\"  {', '.join(features[:5])}{'...' if len(features) > 5 else ''}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Processed Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "output_dir = Path('../data/processed')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save features\n",
    "features_file = output_dir / 'features.csv'\n",
    "X_selected.to_csv(features_file)\n",
    "print(f\"Saved selected features to {features_file}\")\n",
    "\n",
    "# Save target\n",
    "target_file = output_dir / 'target.csv'\n",
    "y.to_csv(target_file)\n",
    "print(f\"Saved target to {target_file}\")\n",
    "\n",
    "# Save pipeline\n",
    "pipeline_file = output_dir / 'feature_pipeline.pkl'\n",
    "pipeline.save(str(pipeline_file))\n",
    "print(f\"Saved feature pipeline to {pipeline_file}\")\n",
    "\n",
    "# Save selector\n",
    "selector_file = output_dir / 'feature_selector.pkl'\n",
    "selector.save(str(selector_file))\n",
    "print(f\"Saved feature selector to {selector_file}\")\n",
    "\n",
    "print(\"\\nAll feature engineering artifacts saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated the complete feature engineering pipeline:\n",
    "\n",
    "1. **Technical Indicators**: Computed 60+ indicators including moving averages, momentum indicators, volatility measures\n",
    "2. **Pattern Features**: Extracted wavelet-based features, DTW similarities, and cluster memberships\n",
    "3. **Transition Features**: Built transition matrices and extracted temporal pattern features\n",
    "4. **Feature Pipeline**: Combined all feature types with proper scaling and missing value handling\n",
    "5. **Feature Selection**: Selected most important features using Random Forest importance and correlation filtering\n",
    "\n",
    "The pipeline is now ready for use in machine learning models for financial prediction tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
