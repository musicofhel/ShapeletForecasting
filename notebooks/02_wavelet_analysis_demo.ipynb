{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wavelet Analysis and Pattern Discovery Demo\n",
    "\n",
    "This notebook demonstrates the wavelet analysis capabilities for financial time series:\n",
    "- Continuous Wavelet Transform (CWT)\n",
    "- Motif Discovery\n",
    "- Shapelet Extraction\n",
    "- Pattern Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath('.'))))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import our modules\n",
    "from src.wavelet_analysis import (\n",
    "    WaveletAnalyzer,\n",
    "    MotifDiscovery,\n",
    "    ShapeletExtractor,\n",
    "    PatternVisualizer\n",
    ")\n",
    "from src.data_collection import StorageManager\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Financial Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize storage manager\n",
    "storage = StorageManager(base_path=\"../data\", storage_format=\"hdf5\")\n",
    "\n",
    "# Load data for a ticker\n",
    "ticker = 'TSLA'\n",
    "timeframe = '1d'\n",
    "\n",
    "data = storage.load_raw_data(tickers=[ticker], timeframes=[timeframe])\n",
    "\n",
    "if ticker in data and timeframe in data[ticker]:\n",
    "    df = data[ticker][timeframe]\n",
    "    print(f\"Loaded {len(df)} days of {ticker} data\")\n",
    "    print(f\"Date range: {df.index[0]} to {df.index[-1]}\")\n",
    "    \n",
    "    # Calculate returns\n",
    "    df['Returns'] = df['Close'].pct_change()\n",
    "    df['LogReturns'] = np.log(df['Close'] / df['Close'].shift(1))\n",
    "    \n",
    "    # Display sample\n",
    "    df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Wavelet Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize wavelet analyzer\n",
    "analyzer = WaveletAnalyzer(wavelet='morl')\n",
    "\n",
    "# Perform CWT on log returns\n",
    "returns = df['LogReturns'].dropna().values\n",
    "coeffs, freqs = analyzer.transform(returns)\n",
    "\n",
    "print(f\"CWT coefficients shape: {coeffs.shape}\")\n",
    "print(f\"Number of scales: {len(analyzer.scales)}\")\n",
    "print(f\"Frequency range: {freqs.min():.4f} - {freqs.max():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract wavelet features\n",
    "features = analyzer.extract_features(coeffs)\n",
    "\n",
    "# Display key features\n",
    "print(\"Wavelet Features:\")\n",
    "print(f\"- Dominant scale: {features['dominant_scale']:.2f}\")\n",
    "print(f\"- Number of ridges detected: {len(features['ridges'])}\")\n",
    "print(f\"- Mean scale energy: {np.mean(features['scale_energy']):.4f}\")\n",
    "print(f\"- Max time energy: {np.max(features['time_energy']):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize wavelet transform\n",
    "viz = PatternVisualizer(figsize=(14, 8))\n",
    "\n",
    "fig = viz.plot_wavelet_transform(\n",
    "    coeffs,\n",
    "    analyzer.scales,\n",
    "    time=df.index[1:],\n",
    "    title=f\"{ticker} Returns - Continuous Wavelet Transform\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect significant patterns in wavelet domain\n",
    "patterns = analyzer.detect_patterns(coeffs, min_duration=5, power_threshold=0.4)\n",
    "\n",
    "print(f\"Found {len(patterns)} significant patterns\")\n",
    "print(\"\\nTop 5 patterns by power:\")\n",
    "for i, pattern in enumerate(patterns[:5]):\n",
    "    print(f\"Pattern {i+1}:\")\n",
    "    print(f\"  - Scale: {pattern['scale']:.2f}\")\n",
    "    print(f\"  - Time range: {pattern['start']} - {pattern['end']}\")\n",
    "    print(f\"  - Duration: {pattern['duration']} days\")\n",
    "    print(f\"  - Max power: {pattern['max_power']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Motif Discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize motif discovery\n",
    "md = MotifDiscovery(window_size=20, min_distance=10)\n",
    "\n",
    "# Find motifs in returns\n",
    "motifs = md.find_motifs(returns, top_k=10)\n",
    "\n",
    "print(f\"Found {len(motifs)} motifs\")\n",
    "print(\"\\nTop 5 motifs:\")\n",
    "for motif in motifs[:5]:\n",
    "    print(f\"\\nMotif {motif['id']}:\")\n",
    "    print(f\"  - Occurrences: {motif['num_occurrences']}\")\n",
    "    print(f\"  - Primary index: {motif['primary_index']}\")\n",
    "    print(f\"  - Mean distance: {motif['mean_distance']:.3f}\")\n",
    "    print(f\"  - Pattern length: {len(motif['pattern'])} days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize motifs\n",
    "fig = viz.plot_motifs(\n",
    "    returns,\n",
    "    motifs,\n",
    "    title=f\"{ticker} - Discovered Return Motifs\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find discords (anomalies)\n",
    "discords = md.find_discords(returns, top_k=5)\n",
    "\n",
    "print(\"Top 5 anomalous patterns (discords):\")\n",
    "for discord in discords:\n",
    "    date_idx = df.index[discord['index'] + 1]  # +1 because returns start from index 1\n",
    "    print(f\"\\nDiscord at {date_idx}:\")\n",
    "    print(f\"  - Anomaly score: {discord['anomaly_score']:.3f}\")\n",
    "    print(f\"  - Distance to nearest neighbor: {discord['distance']:.3f}\")\n",
    "    print(f\"  - Pattern length: {len(discord['pattern'])} days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract motif features for analysis\n",
    "motif_features = md.get_motif_features(motifs)\n",
    "print(\"Motif feature statistics:\")\n",
    "motif_features.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Shapelet Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create labels based on future returns\n",
    "# Label 1: Positive future returns (bullish)\n",
    "# Label 0: Negative future returns (bearish)\n",
    "future_window = 5\n",
    "future_returns = pd.Series(returns).rolling(future_window).mean().shift(-future_window).fillna(0)\n",
    "labels = (future_returns > 0).astype(int).values\n",
    "\n",
    "print(f\"Label distribution:\")\n",
    "print(f\"  - Bearish (0): {np.sum(labels == 0)} ({np.mean(labels == 0)*100:.1f}%)\")\n",
    "print(f\"  - Bullish (1): {np.sum(labels == 1)} ({np.mean(labels == 1)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize shapelet extractor\n",
    "extractor = ShapeletExtractor(\n",
    "    min_length=10,\n",
    "    max_length=30,\n",
    "    num_shapelets=20,\n",
    "    quality_threshold=0.1\n",
    ")\n",
    "\n",
    "# Extract shapelets (this may take a while)\n",
    "print(\"Extracting shapelets...\")\n",
    "shapelets = extractor.extract_shapelets(returns, labels, n_jobs=1)\n",
    "\n",
    "print(f\"\\nExtracted {len(shapelets)} shapelets\")\n",
    "print(\"\\nTop 5 shapelets by quality:\")\n",
    "for i, shapelet in enumerate(shapelets[:5]):\n",
    "    print(f\"\\nShapelet {i+1}:\")\n",
    "    print(f\"  - Quality: {shapelet['quality']:.3f}\")\n",
    "    print(f\"  - Length: {len(shapelet['pattern'])} days\")\n",
    "    print(f\"  - Threshold: {shapelet['threshold']:.3f}\")\n",
    "    print(f\"  - Mean distance: {shapelet['mean_distance']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize shapelets\n",
    "fig = viz.plot_shapelets(\n",
    "    shapelets[:12],\n",
    "    title=f\"{ticker} - Discriminative Shapelets\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get shapelet features\n",
    "shapelet_features = extractor.get_shapelet_features()\n",
    "print(\"Shapelet feature statistics:\")\n",
    "shapelet_features[['length', 'quality', 'threshold', 'trend']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Pattern Similarity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare patterns from motifs and shapelets\n",
    "all_patterns = []\n",
    "pattern_labels = []\n",
    "\n",
    "# Add top motif patterns\n",
    "for i, motif in enumerate(motifs[:5]):\n",
    "    all_patterns.append(motif['pattern'])\n",
    "    pattern_labels.append(f'Motif {i+1}')\n",
    "\n",
    "# Add top shapelet patterns\n",
    "for i, shapelet in enumerate(shapelets[:5]):\n",
    "    # Pad or truncate to match motif length\n",
    "    pattern = shapelet['pattern']\n",
    "    if len(pattern) < 20:\n",
    "        pattern = np.pad(pattern, (0, 20 - len(pattern)), mode='constant')\n",
    "    else:\n",
    "        pattern = pattern[:20]\n",
    "    all_patterns.append(pattern)\n",
    "    pattern_labels.append(f'Shapelet {i+1}')\n",
    "\n",
    "# Create similarity heatmap\n",
    "fig = viz.plot_pattern_heatmap(\n",
    "    all_patterns,\n",
    "    labels=pattern_labels,\n",
    "    title=\"Pattern Similarity Matrix\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Interactive Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive scalogram\n",
    "interactive_fig = viz.create_interactive_scalogram(\n",
    "    coeffs,\n",
    "    analyzer.scales,\n",
    "    time=np.arange(len(returns)),\n",
    "    original_data=returns,\n",
    "    title=f\"{ticker} - Interactive Wavelet Scalogram\"\n",
    ")\n",
    "interactive_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive motif plot\n",
    "interactive_motif_fig = viz.create_interactive_motif_plot(\n",
    "    returns,\n",
    "    motifs,\n",
    "    title=f\"{ticker} - Interactive Motif Discovery\"\n",
    ")\n",
    "interactive_motif_fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Analysis Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save shapelets for the ticker\n",
    "shapelet_data = {\n",
    "    timeframe: [s['pattern'] for s in shapelets]\n",
    "}\n",
    "storage.save_shapelets(shapelet_data, ticker)\n",
    "\n",
    "# Save wavelet features\n",
    "wavelet_features_df = pd.DataFrame([features])\n",
    "storage.save_processed_data(\n",
    "    wavelet_features_df,\n",
    "    f'{ticker}_wavelet_features',\n",
    "    category='wavelet_analysis'\n",
    ")\n",
    "\n",
    "# Save motif features\n",
    "storage.save_processed_data(\n",
    "    motif_features,\n",
    "    f'{ticker}_motif_features',\n",
    "    category='wavelet_analysis'\n",
    ")\n",
    "\n",
    "# Save shapelet features\n",
    "storage.save_processed_data(\n",
    "    shapelet_features,\n",
    "    f'{ticker}_shapelet_features',\n",
    "    category='wavelet_analysis'\n",
    ")\n",
    "\n",
    "print(f\"Analysis results saved for {ticker}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Multi-Ticker Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze multiple tickers\n",
    "tickers_to_analyze = ['TSLA', 'GME', 'AMC', 'NVDA', 'COIN']\n",
    "analysis_results = {}\n",
    "\n",
    "for ticker in tickers_to_analyze:\n",
    "    print(f\"\\nAnalyzing {ticker}...\")\n",
    "    \n",
    "    # Load data\n",
    "    data = storage.load_raw_data(tickers=[ticker], timeframes=['1d'])\n",
    "    \n",
    "    if ticker not in data or '1d' not in data[ticker]:\n",
    "        print(f\"  No data found for {ticker}\")\n",
    "        continue\n",
    "    \n",
    "    df = data[ticker]['1d']\n",
    "    returns = np.diff(np.log(df['Close'].values))\n",
    "    \n",
    "    # Wavelet analysis\n",
    "    coeffs, _ = analyzer.transform(returns)\n",
    "    features = analyzer.extract_features(coeffs)\n",
    "    \n",
    "    # Store results\n",
    "    analysis_results[ticker] = {\n",
    "        'dominant_scale': features['dominant_scale'],\n",
    "        'num_ridges': len(features['ridges']),\n",
    "        'mean_energy': np.mean(features['scale_energy']),\n",
    "        'volatility': np.std(returns)\n",
    "    }\n",
    "    \n",
    "    print(f\"  Dominant scale: {features['dominant_scale']:.2f}\")\n",
    "    print(f\"  Volatility: {np.std(returns):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare analysis results\n",
    "results_df = pd.DataFrame(analysis_results).T\n",
    "results_df = results_df.sort_values('volatility', ascending=False)\n",
    "\n",
    "# Plot comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Dominant scale\n",
    "axes[0, 0].bar(results_df.index, results_df['dominant_scale'])\n",
    "axes[0, 0].set_title('Dominant Wavelet Scale')\n",
    "axes[0, 0].set_ylabel('Scale')\n",
    "\n",
    "# Number of ridges\n",
    "axes[0, 1].bar(results_df.index, results_df['num_ridges'])\n",
    "axes[0, 1].set_title('Number of Wavelet Ridges')\n",
    "axes[0, 1].set_ylabel('Count')\n",
    "\n",
    "# Mean energy\n",
    "axes[1, 0].bar(results_df.index, results_df['mean_energy'])\n",
    "axes[1, 0].set_title('Mean Wavelet Energy')\n",
    "axes[1, 0].set_ylabel('Energy')\n",
    "\n",
    "# Volatility\n",
    "axes[1, 1].bar(results_df.index, results_df['volatility'])\n",
    "axes[1, 1].set_title('Return Volatility')\n",
    "axes[1, 1].set_ylabel('Std Dev')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nAnalysis Summary:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Wavelet Analysis**: Decomposed financial returns into time-frequency components\n",
    "2. **Motif Discovery**: Found recurring patterns in the time series\n",
    "3. **Shapelet Extraction**: Identified discriminative subsequences for classification\n",
    "4. **Pattern Visualization**: Created both static and interactive visualizations\n",
    "5. **Multi-ticker Comparison**: Analyzed patterns across different stocks\n",
    "\n",
    "The discovered patterns and shapelets can be used as features for:\n",
    "- Price movement prediction\n",
    "- Anomaly detection\n",
    "- Market regime identification\n",
    "- Trading strategy development"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
